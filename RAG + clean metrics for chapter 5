[1mdiff --git a/rag_langchain.py b/rag_langchain.py[m
[1mindex 1bb490f..bc34eb4 100644[m
[1m--- a/rag_langchain.py[m
[1m+++ b/rag_langchain.py[m
[36m@@ -1,9 +1,11 @@[m
 from __future__ import annotations[m
 [m
 import hashlib[m
[32m+[m[32mimport json[m
 import os[m
[32m+[m[32mimport time[m
 from pathlib import Path[m
[31m-from typing import Any, Dict, List, Optional[m
[32m+[m[32mfrom typing import Any, Dict, List, Optional, Tuple[m
 [m
 import pandas as pd[m
 from dotenv import load_dotenv[m
[36m@@ -15,6 +17,16 @@[m [mfrom langchain_core.prompts import ChatPromptTemplate[m
 from langchain_community.document_loaders import PyPDFLoader[m
 from langchain_community.vectorstores import FAISS[m
 [m
[32m+[m[32m# =============================================================================[m
[32m+[m[32m# rag_langchain.py[m
[32m+[m[32m# -----------------------------------------------------------------------------[m
[32m+[m[32m# RAG robuste + logs "jury DS" (PERF/CONFIG/CORPUS) sans casser le pipeline:[m
[32m+[m[32m# - mÃªmes signatures (rag_chain(inputs)->dict)[m
[32m+[m[32m# - mÃªmes env vars que ton projet[m
[32m+[m[32m# - logs activables/dÃ©sactivables par env (par dÃ©faut ON en HF)[m
[32m+[m[32m# - logs lisibles + exploitables pour Chapitre 5 (latence + paramÃ¨tres)[m
[32m+[m[32m# =============================================================================[m
[32m+[m
 # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Env / Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[m
 load_dotenv()[m
 BASE_DIR = Path(__file__).resolve().parent[m
[36m@@ -36,6 +48,38 @@[m [mFINGERPRINT_PATH = FAISS_DIR / "fingerprint.txt"[m
 [m
 OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()[m
 [m
[32m+[m[32m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Logging / Perf â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[m
[32m+[m[32m# Active/dÃ©sactive logs perf : 1/0. Par dÃ©faut: 1 sur HF, 0 en local si tu veux.[m
[32m+[m[32mPERF_LOG = os.getenv("PERF_LOG", "1").strip() not in {"0", "false", "False", "no", "NO"}[m
[32m+[m[32mPERF_LOG_LEVEL = os.getenv("PERF_LOG_LEVEL", "INFO").strip().upper()  # INFO|DEBUG[m
[32m+[m[32mPERF_LOG_JSON = os.getenv("PERF_LOG_JSON", "0").strip() in {"1", "true", "True", "yes", "YES"}[m
[32m+[m
[32m+[m[32m# Identifiant utile pour regrouper les logs (build/tag)[m
[32m+[m[32mAPP_VERSION = os.getenv("APP_VERSION", "").strip()  # optionnel[m
[32m+[m[32mGIT_SHA = os.getenv("GIT_SHA", "").strip()          # optionnel[m
[32m+[m
[32m+[m[32mdef _log(event: str, payload: Dict[str, Any]) -> None:[m
[32m+[m[32m    """Logs stables et faciles Ã  grep : prefix [PERF] + event."""[m
[32m+[m[32m    if not PERF_LOG:[m
[32m+[m[32m        return[m
[32m+[m[32m    base = {[m
[32m+[m[32m        "event": event,[m
[32m+[m[32m        "ts": round(time.time(), 3),[m
[32m+[m[32m    }[m
[32m+[m[32m    if APP_VERSION:[m
[32m+[m[32m        base["app_version"] = APP_VERSION[m
[32m+[m[32m    if GIT_SHA:[m
[32m+[m[32m        base["git_sha"] = GIT_SHA[m
[32m+[m
[32m+[m[32m    data = {**base, **payload}[m
[32m+[m[32m    if PERF_LOG_JSON:[m
[32m+[m[32m        print("[PERF] " + json.dumps(data, ensure_ascii=False))[m
[32m+[m[32m    else:[m
[32m+[m[32m        # Format "clÃ©=val" bien lisible et stable[m
[32m+[m[32m        parts = [f"{k}={data[k]}" for k in sorted(data.keys())][m
[32m+[m[32m        print("[PERF] " + " ".join(parts))[m
[32m+[m
[32m+[m
 # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Utils â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[m
 def _ensure_dir_writable(dir_path: Path) -> None:[m
     dir_path.mkdir(parents=True, exist_ok=True)[m
[36m@@ -68,7 +112,7 @@[m [mdef _corpus_fingerprint() -> str:[m
     if not DOCS_DIR.exists():[m
         return "no_corpus"[m
 [m
[31m-    files = [][m
[32m+[m[32m    files: List[Path] = [][m
     for p in DOCS_DIR.glob("*"):[m
         if p.suffix.lower() in {".txt", ".pdf", ".xlsx"}:[m
             files.append(p)[m
[36m@@ -80,6 +124,39 @@[m [mdef _corpus_fingerprint() -> str:[m
     return h.hexdigest()[:16][m
 [m
 [m
[32m+[m[32mdef _corpus_stats() -> Dict[str, Any]:[m
[32m+[m[32m    """Stats simples, utiles pour Chapitre 5 (taille corpus, nb fichiers, etc.)."""[m
[32m+[m[32m    stats: Dict[str, Any] = {[m
[32m+[m[32m        "docs_dir_exists": DOCS_DIR.exists(),[m
[32m+[m[32m        "pdf_exists": PDF_PATH.exists(),[m
[32m+[m[32m        "erreurs_xlsx_exists": ERREURS_XLSX.exists(),[m
[32m+[m[32m        "remed_xlsx_exists": REMED_XLSX.exists(),[m
[32m+[m[32m        "n_txt": 0,[m
[32m+[m[32m        "n_pdf": 0,[m
[32m+[m[32m        "n_xlsx": 0,[m
[32m+[m[32m        "bytes_total": 0,[m
[32m+[m[32m    }[m
[32m+[m[32m    if not DOCS_DIR.exists():[m
[32m+[m[32m        return stats[m
[32m+[m
[32m+[m[32m    for p in DOCS_DIR.glob("*"):[m
[32m+[m[32m        suf = p.suffix.lower()[m
[32m+[m[32m        if suf not in {".txt", ".pdf", ".xlsx"}:[m
[32m+[m[32m            continue[m
[32m+[m[32m        try:[m
[32m+[m[32m            size = p.stat().st_size[m
[32m+[m[32m        except Exception:[m
[32m+[m[32m            size = 0[m
[32m+[m[32m        stats["bytes_total"] += int(size)[m
[32m+[m[32m        if suf == ".txt":[m
[32m+[m[32m            stats["n_txt"] += 1[m
[32m+[m[32m        elif suf == ".pdf":[m
[32m+[m[32m            stats["n_pdf"] += 1[m
[32m+[m[32m        else:[m
[32m+[m[32m            stats["n_xlsx"] += 1[m
[32m+[m[32m    return stats[m
[32m+[m
[32m+[m
 # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load corpus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[m
 def _load_pdf_docs(pdf_path: Path) -> List[Document]:[m
     if not pdf_path.exists():[m
[36m@@ -102,12 +179,7 @@[m [mdef _load_txt_docs(docs_dir: Path) -> List[Document]:[m
         txt = p.read_text(encoding="utf-8", errors="ignore").strip()[m
         if not txt:[m
             continue[m
[31m-        docs.append([m
[31m-            Document([m
[31m-                page_content=txt,[m
[31m-                metadata={"type": "txt", "source": str(p)},[m
[31m-            )[m
[31m-        )[m
[32m+[m[32m        docs.append(Document(page_content=txt, metadata={"type": "txt", "source": str(p)}))[m
     return docs[m
 [m
 [m
[36m@@ -120,7 +192,7 @@[m [mdef _load_excel_as_docs(xlsx_path: Path, default_type: str) -> List[Document]:[m
 [m
     docs: List[Document] = [][m
     for idx, row in df.iterrows():[m
[31m-        parts = [][m
[32m+[m[32m        parts: List[str] = [][m
         for col in df.columns:[m
             val = row[col][m
             if pd.isna(val) or str(val).strip() == "":[m
[36m@@ -169,6 +241,8 @@[m [m_VECTORSTORE: Optional[FAISS] = None[m
 [m
 [m
 def _build_vectorstore() -> FAISS:[m
[32m+[m[32m    t0 = time.perf_counter()[m
[32m+[m
     docs = _load_corpus_docs()[m
     if not docs:[m
         raise RuntimeError([m
[36m@@ -177,8 +251,12 @@[m [mdef _build_vectorstore() -> FAISS:[m
             f"- PDF optionnel: {PDF_PATH}\n"[m
         )[m
 [m
[32m+[m[32m    t1 = time.perf_counter()[m
     chunks = _split_docs(docs)[m
[32m+[m[32m    t2 = time.perf_counter()[m
[32m+[m
     store = FAISS.from_documents(chunks, _embeddings())[m
[32m+[m[32m    t3 = time.perf_counter()[m
 [m
     FAISS_DIR.mkdir(parents=True, exist_ok=True)[m
     _ensure_dir_writable(FAISS_DIR)[m
[36m@@ -186,6 +264,29 @@[m [mdef _build_vectorstore() -> FAISS:[m
 [m
     fp = _corpus_fingerprint()[m
     FINGERPRINT_PATH.write_text(fp, encoding="utf-8")[m
[32m+[m
[32m+[m[32m    t4 = time.perf_counter()[m
[32m