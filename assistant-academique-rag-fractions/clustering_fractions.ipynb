{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Fractions – Profils d’erreurs (RQ2)\n",
        "\n",
        "Objectif : **constituer des groupes de besoin** à partir des **profils d’erreurs** des élèves sur les **fractions**.\n",
        "\n",
        "Ce notebook suppose un fichier : `data/students/responses.csv` avec au minimum :\n",
        "\n",
        "- `student_id`\n",
        "- `error_tags` (tags séparés par `|` si plusieurs)\n",
        "\n",
        "Exemple :\n",
        "```csv\n",
        "student_id,item_id,skill,is_correct,error_tags\n",
        "E01,Q1,add_fractions,0,add_denominators|no_common_denominator\n",
        "```\n",
        "\n",
        "Sorties produites :\n",
        "- choix d’un **K** (silhouette)\n",
        "- clusters + **interprétation pédagogique** (tags dominants)\n",
        "- export `data/students/groups_of_need.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 1) Imports & chemins\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "BASE_DIR = Path.cwd()\n",
        "RESPONSES_CSV = Path(os.getenv(\"RESPONSES_CSV\", str(BASE_DIR / \"data\" / \"students\" / \"responses.csv\")))\n",
        "OUTPUT_CSV = Path(os.getenv(\"GROUPS_OUTPUT_CSV\", str(BASE_DIR / \"data\" / \"students\" / \"groups_of_need.csv\")))\n",
        "\n",
        "print(\"RESPONSES_CSV:\", RESPONSES_CSV)\n",
        "print(\"OUTPUT_CSV   :\", OUTPUT_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 2) Charger les données\n",
        "if not RESPONSES_CSV.exists():\n",
        "    raise FileNotFoundError(f\"Fichier introuvable: {RESPONSES_CSV}\")\n",
        "\n",
        "df = pd.read_csv(RESPONSES_CSV)\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Nettoyage / parsing des `error_tags`\n",
        "\n",
        "- `error_tags` peut être vide si l’item est correct.\n",
        "- on transforme en liste de tags par ligne\n",
        "- on agrège par élève pour obtenir un profil (fréquences de tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 3) Parser les tags\n",
        "def split_tags(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    x = str(x).strip()\n",
        "    if x == \"\":\n",
        "        return []\n",
        "    return [t.strip() for t in x.split(\"|\") if t.strip()]\n",
        "\n",
        "df[\"tags_list\"] = df.get(\"error_tags\", pd.Series([\"\"]*len(df))).apply(split_tags)\n",
        "\n",
        "# Quelques stats rapides\n",
        "n_empty = (df[\"tags_list\"].apply(len) == 0).sum()\n",
        "print(\"Lignes sans tags:\", n_empty, \"/\", len(df))\n",
        "\n",
        "df[[\"student_id\"] + [c for c in df.columns if c in (\"item_id\",\"skill\",\"is_correct\",\"error_tags\",\"tags_list\")]].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Construction de la matrice `élève × tag`\n",
        "\n",
        "On construit une matrice de comptage (ou fréquence) :  \n",
        "- lignes = élèves  \n",
        "- colonnes = tags d’erreurs  \n",
        "- valeurs = nombre d’occurrences (par défaut)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 4) Matrice élève x tag (comptage)\n",
        "students = sorted(df[\"student_id\"].astype(str).unique().tolist())\n",
        "\n",
        "# Liste des tags présents\n",
        "all_tags = sorted({t for tags in df[\"tags_list\"] for t in tags})\n",
        "print(\"Nb élèves:\", len(students))\n",
        "print(\"Nb tags  :\", len(all_tags))\n",
        "print(\"Exemples tags:\", all_tags[:15])\n",
        "\n",
        "# Construire la matrice de comptage\n",
        "student_index = {s:i for i,s in enumerate(students)}\n",
        "tag_index = {t:j for j,t in enumerate(all_tags)}\n",
        "\n",
        "X = np.zeros((len(students), len(all_tags)), dtype=float)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    s = str(row[\"student_id\"])\n",
        "    i = student_index[s]\n",
        "    for t in row[\"tags_list\"]:\n",
        "        j = tag_index[t]\n",
        "        X[i, j] += 1.0\n",
        "\n",
        "# Option: passer en fréquences par élève (utile si nb items très différent selon élèves)\n",
        "row_sums = X.sum(axis=1, keepdims=True)\n",
        "X_freq = np.divide(X, row_sums, out=np.zeros_like(X), where=row_sums!=0)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Choisir le nombre de clusters (K)\n",
        "\n",
        "On teste plusieurs K (ex: 2 → 8) et on calcule le **silhouette score**.  \n",
        "⚠️ Il faut au moins 2 élèves et une variance minimale.\n",
        "\n",
        "> Si tu as très peu d’élèves, ne cherche pas à sur-optimiser : l’interprétation pédagogique prime.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 5) Recherche du meilleur K (silhouette)\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def try_k_values(X_used, k_min=2, k_max=8, random_state=42):\n",
        "    scores = []\n",
        "    for k in range(k_min, k_max+1):\n",
        "        if X_used.shape[0] <= k:\n",
        "            continue\n",
        "        km = KMeans(n_clusters=k, n_init=10, random_state=random_state)\n",
        "        labels = km.fit_predict(X_used)\n",
        "        # silhouette nécessite au moins 2 clusters non vides\n",
        "        if len(set(labels)) < 2:\n",
        "            continue\n",
        "        score = silhouette_score(X_used, labels)\n",
        "        scores.append((k, score))\n",
        "    return scores\n",
        "\n",
        "scores = try_k_values(X_freq if X_freq.shape[1] > 0 else X)\n",
        "\n",
        "scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 5b) Visualiser les scores (simple)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if scores:\n",
        "    ks = [k for k,_ in scores]\n",
        "    ss = [s for _,s in scores]\n",
        "    plt.figure()\n",
        "    plt.plot(ks, ss, marker=\"o\")\n",
        "    plt.xlabel(\"K (nombre de clusters)\")\n",
        "    plt.ylabel(\"Silhouette score\")\n",
        "    plt.title(\"Choix de K par silhouette\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Pas assez de données pour calculer la silhouette (ajoute des élèves/items).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Entraîner le clustering final\n",
        "\n",
        "Par défaut :\n",
        "- on prend le K avec silhouette max (si disponible)\n",
        "- sinon on fixe K=3 (valeur raisonnable pour des groupes de besoin)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 6) Fit final\n",
        "DEFAULT_K = 3\n",
        "\n",
        "if scores:\n",
        "    best_k = max(scores, key=lambda x: x[1])[0]\n",
        "else:\n",
        "    best_k = DEFAULT_K\n",
        "\n",
        "print(\"K retenu:\", best_k)\n",
        "\n",
        "km = KMeans(n_clusters=best_k, n_init=20, random_state=42)\n",
        "labels = km.fit_predict(X_freq if X_freq.shape[1] > 0 else X)\n",
        "\n",
        "cluster_df = pd.DataFrame({\n",
        "    \"student_id\": students,\n",
        "    \"cluster\": labels\n",
        "}).sort_values([\"cluster\", \"student_id\"]).reset_index(drop=True)\n",
        "\n",
        "cluster_df.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Interprétation pédagogique des clusters\n",
        "\n",
        "On calcule, pour chaque cluster, les **tags dominants** (fréquence moyenne la plus élevée).  \n",
        "C’est cette partie qui te sert directement dans le mémoire : *cluster = profil d’erreurs = besoin de remédiation*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 7) Tags dominants par cluster\n",
        "tag_names = np.array(all_tags)\n",
        "\n",
        "X_used = X_freq if X_freq.shape[1] > 0 else X\n",
        "cluster_profiles = []\n",
        "\n",
        "for c in sorted(cluster_df[\"cluster\"].unique()):\n",
        "    idx = cluster_df.index[cluster_df[\"cluster\"] == c].to_list()\n",
        "    # Moyenne des vecteurs d'erreurs dans le cluster\n",
        "    mean_vec = X_used[idx].mean(axis=0) if len(idx) else np.zeros((X_used.shape[1],))\n",
        "    top_idx = np.argsort(mean_vec)[::-1][:8]\n",
        "    top_tags = [(tag_names[j], float(mean_vec[j])) for j in top_idx if mean_vec[j] > 0]\n",
        "    cluster_profiles.append({\n",
        "        \"cluster\": c,\n",
        "        \"n_students\": int((cluster_df[\"cluster\"] == c).sum()),\n",
        "        \"top_tags\": top_tags\n",
        "    })\n",
        "\n",
        "cluster_profiles\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 7b) Présentation lisible\n",
        "for prof in cluster_profiles:\n",
        "    print(f\"\\n=== Cluster {prof['cluster']} | n={prof['n_students']} ===\")\n",
        "    if not prof[\"top_tags\"]:\n",
        "        print(\"Aucun tag dominant (données insuffisantes ou erreurs non taguées).\")\n",
        "        continue\n",
        "    for t, v in prof[\"top_tags\"]:\n",
        "        print(f\"- {t}: {v:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Export : groupes de besoin\n",
        "\n",
        "On exporte `groups_of_need.csv` avec :\n",
        "- `student_id`\n",
        "- `cluster`\n",
        "- `profile_summary` (tags dominants)\n",
        "\n",
        "Ce fichier sert ensuite :\n",
        "- à l’enseignant (groupes)\n",
        "- à l’assistant (remédiation RAG par cluster)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 8) Construire un résumé de profil par cluster\n",
        "summary_by_cluster = {}\n",
        "for prof in cluster_profiles:\n",
        "    tags_only = [t for t,_ in prof[\"top_tags\"]][:5]\n",
        "    summary_by_cluster[prof[\"cluster\"]] = \", \".join(tags_only) if tags_only else \"\"\n",
        "\n",
        "cluster_df[\"profile_summary\"] = cluster_df[\"cluster\"].map(summary_by_cluster)\n",
        "\n",
        "# Sauvegarde\n",
        "OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
        "cluster_df.to_csv(OUTPUT_CSV, index=False)\n",
        "print(\"✅ Exporté:\", OUTPUT_CSV)\n",
        "cluster_df.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Vérification qualitative (mini-liste par groupe)\n",
        "\n",
        "Affiche les élèves par cluster.  \n",
        "C’est la partie “enseignant-friendly”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 9) Liste des élèves par groupe\n",
        "for c in sorted(cluster_df[\"cluster\"].unique()):\n",
        "    group = cluster_df[cluster_df[\"cluster\"] == c][\"student_id\"].tolist()\n",
        "    print(f\"\\nGroupe {c} ({len(group)} élèves) – Profil: {summary_by_cluster.get(c,'')}\")\n",
        "    print(\", \".join(group))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) (Option) Lier cluster → remédiation via RAG\n",
        "\n",
        "Ici, on montre comment une **question RAG** peut être générée à partir du profil du cluster,\n",
        "afin de récupérer des ressources adaptées (cours, erreurs fréquentes, exercices gradués).\n",
        "\n",
        "> Nécessite `rag_langchain.py` configuré et un corpus Fractions riche.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ✅ 10) Exemple: requête RAG par cluster (option)\n",
        "try:\n",
        "    from rag_langchain import rag_chain\n",
        "    for prof in cluster_profiles:\n",
        "        c = prof[\"cluster\"]\n",
        "        tags = [t for t,_ in prof[\"top_tags\"]][:3]\n",
        "        if not tags:\n",
        "            continue\n",
        "        q = (\n",
        "            \"Propose une remédiation courte sur les fractions pour les erreurs suivantes: \"\n",
        "            + \", \".join(tags)\n",
        "            + \". Donne une explication + 2 exercices gradués.\"\n",
        "        )\n",
        "        r = rag_chain({\"question\": q})\n",
        "        print(f\"\\n--- Remédiation pour cluster {c} ({', '.join(tags)}) ---\")\n",
        "        print((r.get('answer','') or '')[:1200])\n",
        "except Exception as e:\n",
        "    print(\"RAG non disponible dans ce notebook (ou corpus manquant):\", e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "clustering_fractions.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}