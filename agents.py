from __future__ import annotations

import os
from pathlib import Path
from typing import Any, Dict, List

import pandas as pd
from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
if not OPENAI_API_KEY:
    raise SystemExit("âŒ OPENAI_API_KEY manquant. Mets-le dans .env")

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "").strip()

BASE_DIR = Path(__file__).resolve().parent

DOCS_DIR = Path(os.getenv("DOCS_DIR", str(BASE_DIR / "data" / "corpus")))
PDF_NAME = os.getenv("PDF_NAME", "Cours_Fractions_5e.pdf")
PDF_PATH = DOCS_DIR / PDF_NAME

ERREURS_XLSX = Path(os.getenv("ERREURS_XLSX", str(DOCS_DIR / "Erreurs_Fractions_5e.xlsx")))
REMED_XLSX = Path(os.getenv("REMED_XLSX", str(DOCS_DIR / "Remediations_Fractions_5e.xlsx")))

RESPONSES_CSV = Path(os.getenv("RESPONSES_CSV", str(BASE_DIR / "data" / "students" / "responses.csv")))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    api_key=OPENAI_API_KEY,  # LangChain rÃ©cent accepte api_key
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ton rag_langchain.py doit exposer `rag_chain` (callable) qui renvoie dict:
# { "answer": str, "source_documents": List[Document] }
from rag_langchain import rag_chain

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langchain.tools import tool  # outil moderne via dÃ©corateur (souvent dispo mÃªme si le reste change)


def _fmt_source(doc) -> str:
    """Formate une source (pdf/excel/txt) de faÃ§on lisible."""
    meta = getattr(doc, "metadata", None) or {}
    src = meta.get("source") or meta.get("file_name") or meta.get("basename") or "unknown"
    src_name = os.path.basename(str(src))

    doc_type = meta.get("type")

    # PDF
    if doc_type == "pdf" and meta.get("page") is not None:
        try:
            page = int(meta["page"]) + 1
        except Exception:
            page = meta["page"]
        return f"{src_name}:{page}"

    # Excel
    if doc_type == "excel":
        sheet = meta.get("sheet", "sheet?")
        row = meta.get("row", None)
        if row is not None:
            return f"{src_name}|{sheet}|row={row}"
        return f"{src_name}|{sheet}"

    return src_name


def _sources_block(source_documents: List[Any]) -> str:
    if not source_documents:
        return "Sources: (aucune)"
    seen, refs = set(), []
    for d in source_documents:
        r = _fmt_source(d)
        if r not in seen:
            seen.add(r)
            refs.append(r)
    refs = refs[:10]
    return "Sources: " + " ; ".join(f"[{r}]" for r in refs)


@tool
def fractions_rag(question: str) -> str:
    """
    RÃ©pond sur les FRACTIONS (niveau 5e) uniquement Ã  partir du corpus local (PDF + Excel).
    Retourne toujours des sources.
    """
    result = rag_chain({"question": question})
    answer = (result.get("answer") or "").strip() or "Je ne sais pas."
    sources = result.get("source_documents") or []
    return f"{answer}\n\n{_sources_block(sources)}"


@tool
def didactic_check(text: str) -> str:
    """
    RÃ©Ã©crit un contenu en version didactique (fractions 5e) : sens, exemple, erreur frÃ©quente.
    """
    prompt = f"""
Tu es un didacticien en mathÃ©matiques (spÃ©cialiste des fractions, niveau 5e).
AmÃ©liore le texte en Ã©vitant les "rÃ¨gles magiques".

Structure obligatoire :
1) IdÃ©e clÃ©
2) Explication (avec sens)
3) Mini-exemple
4) Erreur frÃ©quente + comment lâ€™Ã©viter

Texte :
{text}

RÃ©Ã©criture :
"""
    return llm.invoke(prompt).content.strip()


def _load_excel(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    xls = pd.ExcelFile(path)
    sheet = xls.sheet_names[0]
    return pd.read_excel(xls, sheet_name=sheet)


@tool
def lookup_error_remediation(error_id: str) -> str:
    """
    RÃ©cupÃ¨re une erreur + remÃ©diation via error_id dans les Excel (erreurs/remÃ©diations).
    """
    eid = (error_id or "").strip()
    if not eid:
        return "âŒ Donne un error_id (ex: add_denominators)."

    err_df = _load_excel(ERREURS_XLSX)
    rem_df = _load_excel(REMED_XLSX)

    if err_df.empty or rem_df.empty:
        return (
            "âŒ Excel introuvables ou vides.\n"
            f"- {ERREURS_XLSX}\n"
            f"- {REMED_XLSX}"
        )

    err_df.columns = [c.strip().lower() for c in err_df.columns]
    rem_df.columns = [c.strip().lower() for c in rem_df.columns]

    if "error_id" not in err_df.columns or "error_id" not in rem_df.columns:
        return "âŒ Les fichiers Excel doivent contenir une colonne `error_id`."

    err = err_df[err_df["error_id"].astype(str).str.strip() == eid]
    rem = rem_df[rem_df["error_id"].astype(str).str.strip() == eid]

    if err.empty and rem.empty:
        return f"Je ne trouve pas lâ€™error_id: {eid}"

    out = [f"ğŸ” error_id = {eid}\n"]

    if not err.empty:
        r = err.iloc[0].to_dict()
        out.append("ğŸ“Œ **Erreur (Excel)**")
        for k, v in r.items():
            if pd.isna(v) or str(v).strip() == "":
                continue
            out.append(f"- {k}: {v}")
        out.append(f"Source: [{ERREURS_XLSX.name}]")

    if not rem.empty:
        r = rem.iloc[0].to_dict()
        out.append("\nğŸ› ï¸ **RemÃ©diation (Excel)**")
        for k, v in r.items():
            if pd.isna(v) or str(v).strip() == "":
                continue
            out.append(f"- {k}: {v}")
        out.append(f"Source: [{REMED_XLSX.name}]")

    return "\n".join(out)


@tool
def groups_from_csv(_: str = "") -> str:
    """
    PrÃ©-analyse simple : agrÃ¨ge les error_tags par Ã©lÃ¨ve (depuis responses.csv),
    puis affiche les 3 tags dominants.
    """
    if not RESPONSES_CSV.exists():
        return (
            f"âŒ Fichier introuvable: {RESPONSES_CSV}\n"
            "CrÃ©e `data/students/responses.csv` avec au minimum: student_id, error_tags."
        )

    df = pd.read_csv(RESPONSES_CSV)
    required = {"student_id", "error_tags"}
    if not required.issubset(df.columns):
        return (
            "âŒ Colonnes manquantes dans responses.csv.\n"
            "Attendu au minimum: student_id, error_tags\n"
            f"Colonnes trouvÃ©es: {list(df.columns)}"
        )

    def split_tags(x):
        if pd.isna(x) or str(x).strip() == "":
            return []
        return [t.strip() for t in str(x).split("|") if t.strip()]

    df["tags_list"] = df["error_tags"].apply(split_tags)

    agg = df.groupby("student_id")["tags_list"].sum().reset_index()
    agg["top_tags"] = agg["tags_list"].apply(
        lambda L: ", ".join(pd.Series(L).value_counts().head(3).index.tolist())
    )

    lines = ["ğŸ§© **PrÃ©-analyse des profils dâ€™erreurs (Fractions 5e)**\n"]
    for _, row in agg.iterrows():
        lines.append(f"- {row['student_id']} â†’ {row['top_tags'] or '(aucune erreur taguÃ©e)'}")

    lines.append(
        "\nğŸ‘‰ Pour un clustering (KMeans/HiÃ©rarchique + silhouette), utilise `clustering_fractions.ipynb` "
        "puis exporte un `groups_of_need.csv`."
    )
    return "\n".join(lines)


@tool
def web_search_tavily(query: str) -> str:
    """
    Recherche web via Tavily (utile pour enrichir / vÃ©rifier des points).
    Si TAVILY_API_KEY est absent, l'outil explique quoi faire.
    """
    if not TAVILY_API_KEY:
        return (
            "âŒ TAVILY_API_KEY manquant dans .env.\n"
            "â¡ï¸ Ajoute TAVILY_API_KEY=... (ou dÃ©sactive lâ€™usage de cet outil)."
        )

    from tavily import TavilyClient

    client = TavilyClient(api_key=TAVILY_API_KEY)

    # RÃ©ponse courte & propre (pas besoin de 40 liens)
    res = client.search(
        query=query,
        search_depth="basic",
        max_results=5,
        include_answer=True,
        include_raw_content=False,
    )

    answer = (res.get("answer") or "").strip()
    results = res.get("results") or []

    lines = []
    if answer:
        lines.append(f"ğŸ§­ **SynthÃ¨se Tavily**\n{answer}\n")

    if results:
        lines.append("ğŸ”— **RÃ©sultats**")
        for r in results[:5]:
            title = (r.get("title") or "").strip()
            url = (r.get("url") or "").strip()
            snippet = (r.get("content") or "").strip()
            if title and url:
                lines.append(f"- {title}\n  {url}\n  {snippet}")

    return "\n".join(lines).strip() or "Aucun rÃ©sultat Tavily."


TOOLS = [
    fractions_rag,
    didactic_check,
    lookup_error_remediation,
    groups_from_csv,
    web_search_tavily,
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent moderne : create_agent (LangChain docs)
try:
    from langchain.agents import create_agent
except Exception as e:
    raise SystemExit(
        "âŒ Ton paquet `langchain` ne fournit pas `create_agent`.\n"
        "â¡ï¸ Fais:  python -m pip install -U langchain\n"
        f"DÃ©tail import: {e}"
    )

SYSTEM_PROMPT = f"""
Tu es un assistant pÃ©dagogique intelligent spÃ©cialisÃ© sur les FRACTIONS (niveau 5e),
dans le cadre dâ€™un mÃ©moire DU Sorbonne Data Analytics.

Corpus local attendu (chemins indicatifs) :
- PDF cours: {PDF_PATH}
- Excel erreurs: {ERREURS_XLSX}
- Excel remÃ©diations: {REMED_XLSX}

RÃ¨gles de dÃ©cision :
- Pour une question de cours/mÃ©thode/erreur/remÃ©diation : utilise dâ€™abord lâ€™outil `fractions_rag`.
- Pour rendre une explication plus pÃ©dagogique : utilise `didactic_check`.
- Pour rÃ©cupÃ©rer une fiche exacte via un tag : utilise `lookup_error_remediation`.
- Pour analyse classe : utilise `groups_from_csv`.
- Pour une vÃ©rification web (hors corpus) : utilise `web_search_tavily` (si disponible).

RÃ¨gle de vÃ©ritÃ© :
- Si lâ€™info nâ€™est pas dans le corpus et que la recherche web nâ€™est pas autorisÃ©e/dispo : dis exactement Â« Je ne sais pas. Â»
- Nâ€™invente jamais de sources.
""".strip()

agent = create_agent(
    llm,
    TOOLS,
    system_prompt=SYSTEM_PROMPT,
)
